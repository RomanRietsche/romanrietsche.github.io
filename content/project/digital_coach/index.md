---
title: Digital Coaching
summary: Investigated how transparently sharing an AI coach's intermediate reasoning, framed with epistemic humility, affects user trust, engagement, and coaching outcomes in educational settings.
tags:
  - Digital Interventions
date: '2022-02-01'

# Optional external URL for project (replaces project detail page).
external_link: ''

image:
  focal_point: Smart

links:
url_code: ''
url_pdf: ''
url_slides: ''
url_video: ''
---

## The Challenge

AI-based coaching systems typically operate as black boxes, delivering recommendations without revealing their internal reasoning. This lack of transparency can erode user trust, particularly when outcomes do not meet expectations. As AI coaches increasingly support learners in setting and pursuing personal development goals, the question arose whether making the AI's reasoning process visible would improve or hinder the user experience, and whether the way that reasoning is framed matters.

## Approach and Methods

The project conducted controlled experiments and real-world field studies with university students who interacted with an AI-based coaching system over the course of a semester. The experimental conditions varied along two dimensions: whether the AI displayed its intermediate reasoning steps to the user, and how that reasoning was framed. The "factive" framing used assertive language ("I know that..."), while the "non-factive" framing used epistemically humble language ("I believe that..."). The studies measured user trust, expectation confirmation, working alliance (the perceived quality of the coach-user relationship), and academic outcomes.

## Key Findings

Displaying the AI's intermediate reasoning in an epistemically humble, non-factive manner ("I believe..." rather than "I know...") significantly improved user satisfaction and trust. This modest framing set realistic expectations, reduced disappointment from inevitable minor errors, and strengthened the working alliance between the AI coach and the user. Students who regularly interacted with the transparently reasoning AI coach reported better progress toward their personal educational goals, and their engagement correlated with higher academic performance.

## Implications

For practitioners designing AI coaching, tutoring, or customer support systems, the findings offer a clear design guideline: expose the AI's reasoning process to users, but frame it with appropriate humility. Assertive language risks creating expectations the system cannot consistently meet, while humble framing builds a more resilient and trusting relationship. This principle extends beyond education to any domain where AI systems provide personalized guidance.

## Team and Funding

The digital coaching research was part of the SCESC Innosuisse Flagship project. It was led by Andreas Goldi (University of St. Gallen) and Prof. Dr. Roman Rietsche (BFH), investigating how AI-driven coaching systems can transparently support learners. The project was funded by Innosuisse as part of the SCESC Flagship (2022 to 2025).
